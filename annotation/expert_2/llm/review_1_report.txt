Paper Title: Multi-Source Unsupervised Hyperparameter Optimization

Paper Abstract: How can we conduct efficient hyperparameter optimization for a completely new task? In this work, we consider a novel setting, where we search for the optimal hyperparameters for a target task of interest using only unlabeled target task and ‘somewhat relevant’ source task datasets. In this setting, it is essential to estimate the ground-truth target task objective using only the available information. We propose estimators to unbiasedly approximate the ground-truth with a desirable variance property. Building on these estimators, we provide a general and tractable hyperparameter optimization procedure for our setting. The experimental evaluations demonstrate that the proposed framework broadens the applications of automated hyperparameter optimization.

Target Review (Reviewer 1):
*Summary\nIn the situation where a given objective is computed with samples from a distribution, e.g. loss on validation data in hyperparameter optimization, this paper proposes a method to construct a surrogate objective using objectives computed on sets of samples each of which is from a different distribution. Basic idea is to use a linear combination of importance sampling estimators. Moreover, the optimal linear combination coefficients are identified in a sense of being optimal in a certain family of convex combination coefficients. This approach has an interesting application that hyperparameters of machine learning deployed on an unseen dataset, importantly, without labels(output) can be optimized as long as the distribution of the input of the unseen dataset is samplable.\n\n\nStrengths\n1. The paper provides an algorithm that can estimate an objective computed on data without requiring access to labels in some optimal sense.\n2. Based on the proposed estimator, a transfer hyperparameter optimization algorithm to solve interesting problems is introduced.\n\n\nWeaknesses\n1. Maybe the novelty of the paper mainly lies in the combination not on inventing something new, which is, however, not certain since my coverage of relevant literature was not extensive.\n2. I can imagine that someone may ask for more experiments of a large scale or of the type exemplified in the intro. On the other hand, the experiments can be regarded as designed concisely to demonstrate the authors' main points.\n\n\nRecommendation\nOverall, I am willing to defend the acceptance of this paper. This combination of transfer HPO and importance sampling estimator seem novel, interesting, and well-demonstrated, with which many interesting applications can be imagined. \n\n\nQuestions\n- On the line right below eq.(2), the loss function L is assumed to be bounded. Is this condition is necessary in proofs of any theoretical ones? It seems that, in all experiments, all losses are unbounded.\n\n\nAdditional feedback*\n- Explicitly emphasizing that Def 3 is motivated by eq.(6) may guide readers better.\n- While reading the paper, the questions arose were mostly answered after a few lines. The reading was pleasant for me and the paper is well-structured.\n

Tone and Sentiment Analysis:
Sentiment: Positive
Sentiment Reason: The reviewer states 'Overall, I am willing to defend the acceptance of this paper' and describes the combination of transfer HPO and importance sampling estimator as 'novel, interesting, and well-demonstrated'.
Tone: Balanced
Tone Reason: The reviewer provides both strengths and weaknesses, and their feedback includes both positive comments ('the reading was pleasant', 'well-structured') and suggestions for improvement ('Explicitly emphasizing that Def3 is motivated by eq.(6) may guide readers better').

Internal Consistency Check:
Consistent_in_itself: True
Consistency_reason: The review maintains a consistent critical viewpoint throughout, praising the paper's methodology and application while also noting some potential weaknesses such as the novelty of the combination and the scale of experiments. The reviewer provides a balanced evaluation, supporting their recommendation with specific strengths and weaknesses, and raises questions and additional feedback that are relevant to the paper's content.

Inter-Review Comparison:
is_consistent_with_others: False
alignment_score: 3
contradictory_points: The target review finds the paper's contribution to be somewhat novel and interesting, while one of the other reviews questions the framing of the problem and suggests alternative simpler baselines that could achieve similar results. The target review also does not raise concerns about the experimental setup, whereas other reviews criticize the limited scope of the experiments and the baselines used.
possible_bias_flags: The target review appears to be more positive than some of the other reviews, which could indicate a bias towards accepting the paper. However, the tone is still critical and suggests areas for improvement.
summary_of_differences: The target review is generally more positive than the other reviews, which raise several concerns about the problem framing, experimental setup, and baselines used. The tone and sentiment of the target review are more constructive, while the other reviews are more critical.

Bias Detection:
bias_detected: True
bias_types: ['Positive Results Bias', 'Novelty Bias']
confidence_score: 7
evidence: The target review is generally more positive than other reviews, praising the paper's methodology and application while downplaying concerns about novelty and experimental setup. The reviewer finds the combination of transfer HPO and importance sampling estimator 'novel, interesting, and well-demonstrated', which contrasts with other reviews that question the framing of the problem and the limited scope of experiments.
suggestion_for_improvements: The reviewer should consider acknowledging potential concerns about the novelty and experimental setup more explicitly, and provide a more balanced evaluation that takes into account the criticisms raised by other reviews. Additionally, the reviewer could suggest ways to address these concerns, such as additional experiments or comparisons to simpler baselines.
